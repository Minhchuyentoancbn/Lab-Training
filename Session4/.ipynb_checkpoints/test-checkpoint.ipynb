{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "011c5973-3726-4859-86b5-8d8835882f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "192a7122-6e71-4906-9ebf-5c56fb8b5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DOC_LENGTH = 500\n",
    "NUM_CLASSES = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f3ec4-7760-4613-9526-373d7b4c592e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "158935e6-a170-4425-9668-091b0d978c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 0-alt.atheism\n",
      "Processing: 1-comp.graphics\n",
      "Processing: 2-comp.os.ms-windows.misc\n",
      "Processing: 3-comp.sys.ibm.pc.hardware\n",
      "Processing: 4-comp.sys.mac.hardware\n",
      "Processing: 5-comp.windows.x\n",
      "Processing: 6-misc.forsale\n",
      "Processing: 7-rec.autos\n",
      "Processing: 8-rec.motorcycles\n",
      "Processing: 9-rec.sport.baseball\n",
      "Processing: 10-rec.sport.hockey\n",
      "Processing: 11-sci.crypt\n",
      "Processing: 12-sci.electronics\n",
      "Processing: 13-sci.med\n",
      "Processing: 14-sci.space\n",
      "Processing: 15-soc.religion.christian\n",
      "Processing: 16-talk.politics.guns\n",
      "Processing: 17-talk.politics.mideast\n",
      "Processing: 18-talk.politics.misc\n",
      "Processing: 19-talk.religion.misc\n",
      "Processing: 0-alt.atheism\n",
      "Processing: 1-comp.graphics\n",
      "Processing: 2-comp.os.ms-windows.misc\n",
      "Processing: 3-comp.sys.ibm.pc.hardware\n",
      "Processing: 4-comp.sys.mac.hardware\n",
      "Processing: 5-comp.windows.x\n",
      "Processing: 6-misc.forsale\n",
      "Processing: 7-rec.autos\n",
      "Processing: 8-rec.motorcycles\n",
      "Processing: 9-rec.sport.baseball\n",
      "Processing: 10-rec.sport.hockey\n",
      "Processing: 11-sci.crypt\n",
      "Processing: 12-sci.electronics\n",
      "Processing: 13-sci.med\n",
      "Processing: 14-sci.space\n",
      "Processing: 15-soc.religion.christian\n",
      "Processing: 16-talk.politics.guns\n",
      "Processing: 17-talk.politics.mideast\n",
      "Processing: 18-talk.politics.misc\n",
      "Processing: 19-talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "gen_data_and_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad9deb39-1053-414f-b671-11e3a6c7a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data('data/w2v/20news-train-raw.txt', 'data/w2v/vocab-raw.txt')\n",
    "encode_data('data/w2v/20news-test-raw.txt', 'data/w2v/vocab-raw.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ff659-c577-48dd-ae4c-aecfb12c93b7",
   "metadata": {},
   "source": [
    "# 2. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6590f792-7d93-4ab5-b651-4babab7bf7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\anacoda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ef8dcd-6ded-4d16-a065-e9678e1c12ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, vocab_size, embedding_size, \n",
    "                 lstm_size, batch_size):\n",
    "        self._vocab_size = vocab_size\n",
    "        self._embedding_size = embedding_size\n",
    "        self._lstm_size = lstm_size\n",
    "        self._batch_size = batch_size\n",
    "\n",
    "        self._data = tf.placeholder(tf.int32, shape=[batch_size, MAX_DOC_LENGTH])\n",
    "        self._labels = tf.placeholder(tf.int32, shape=[batch_size, ])\n",
    "        self._sentence_lengths = tf.placeholder(tf.int32, shape=[batch_size, ])\n",
    "        self._final_tokens = tf.placeholder(tf.int32, shape=[batch_size, ])\n",
    "\n",
    "\n",
    "    def embedding_layer(self, indices):\n",
    "        pretrained_vectors = []\n",
    "        pretrained_vectors.append(np.zeros(self._embedding_size))\n",
    "        np.random.seed(2022)\n",
    "        for _ in range(self._vocab_size + 1):\n",
    "            pretrained_vectors.append(np.random.normal(size=self._embedding_size))\n",
    "        \n",
    "        pretrained_vectors = np.array(pretrained_vectors)\n",
    "        \n",
    "        self._embedding_matrix = tf.get_variable(\n",
    "            name='embedding',\n",
    "            shape=(self._vocab_size + 2, self._embedding_size),\n",
    "            initializer=tf.constant_initializer(pretrained_vectors)\n",
    "        )\n",
    "        \n",
    "        return tf.nn.embedding_lookup(self._embedding_matrix, indices)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def LSTM_layer(self, embeddings):\n",
    "        lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(self._lstm_size)\n",
    "        zero_state = tf.zeros(shape=(self._batch_size, self._lstm_size))\n",
    "        initial_state = tf.nn.rnn_cell.LSTMStateTuple(zero_state, zero_state)\n",
    "        \n",
    "        lstm_inputs = tf.unstack(\n",
    "            tf.transpose(embeddings, perm=[1, 0, 2])\n",
    "        )\n",
    "        lstm_outputs, last_state = tf.nn.static_rnn(\n",
    "            cell=lstm_cell,\n",
    "            inputs=lstm_inputs,\n",
    "            initial_state=initial_state,\n",
    "            sequence_length=self._sentence_lengths\n",
    "        )\n",
    "        \n",
    "        lstm_outputs = tf.unstack(\n",
    "            tf.transpose(lstm_outputs, perm=[1, 0, 2])\n",
    "        )\n",
    "        lstm_outputs = tf.concat(lstm_outputs, axis=0)\n",
    "        \n",
    "        mask = tf.sequence_mask(\n",
    "            lengths=self._sentence_lengths,\n",
    "            maxlen=MAX_DOC_LENGTH,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "        mask = tf.concat(tf.unstack(mask, axis=0), axis=0)\n",
    "        mask = tf.expand_dims(mask, -1)\n",
    "        \n",
    "        lstm_outputs = mask * lstm_outputs\n",
    "        lstm_outputs_split = tf.split(lstm_outputs, num_or_size_splits=self._batch_size)\n",
    "        lstm_outputs_sum = tf.reduce_sum(lstm_outputs_split, axis=1)\n",
    "        lstm_outputs_average = lstm_outputs_sum / tf.expand_dims(\n",
    "            tf.cast(self._sentence_lengths, tf.float32),\n",
    "            -1\n",
    "        )\n",
    "        return lstm_outputs_average\n",
    "\n",
    "    \n",
    "    \n",
    "    def build_graph(self):\n",
    "        embeddings = self.embedding_layer(self._data)\n",
    "        lstm_outputs = self.LSTM_layer(embeddings)\n",
    "        \n",
    "        weights = tf.get_variable(\n",
    "            name='final_layer_weights',\n",
    "            shape=(self._lstm_size, NUM_CLASSES),\n",
    "            initializer=tf.random_normal_initializer(seed=2022)\n",
    "        )\n",
    "        biases = tf.get_variable(\n",
    "            name='final_layer_biases',\n",
    "            shape=(NUM_CLASSES),\n",
    "            initializer=tf.random_normal_initializer(seed=2022)\n",
    "        )\n",
    "        \n",
    "        logits = tf.matmul(lstm_outputs, weights) + biases\n",
    "        \n",
    "        labels_one_hot = tf.one_hot(\n",
    "            indices=self._labels,\n",
    "            depth=NUM_CLASSES,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=labels_one_hot,\n",
    "            logits=logits\n",
    "        )\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        \n",
    "        probs = tf.nn.softmax(logits)\n",
    "        predicted_labels = tf.argmax(probs, axis=1)\n",
    "        predicted_labels = tf.squeeze(predicted_labels)\n",
    "        \n",
    "        return predicted_labels, loss\n",
    "\n",
    "    \n",
    "    def trainer(self, loss, learning_rate):\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "        return train_op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32238cb7-a681-47c4-88d0-3d9c25609a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader:\n",
    "    def __init__(self, data_path, batch_size):\n",
    "        self._batch_size = batch_size\n",
    "        with open(data_path) as f:\n",
    "            d_lines = f.read().splitlines()\n",
    "            \n",
    "        self._data = []\n",
    "        self._labels = []\n",
    "        self._sentence_lengths = []\n",
    "        self._final_tokens = []\n",
    "        for data_id, line in enumerate(d_lines):\n",
    "            features = line.split('<fff>')\n",
    "            label, doc_id, sentence_length = int(features[0]), int(features[1]), int(features[2])\n",
    "            tokens = features[3].split()\n",
    "\n",
    "            self._data.append(tokens)\n",
    "            self._sentence_lengths.append(sentence_length)\n",
    "            self._labels.append(label)\n",
    "            self._final_tokens.append(tokens[-1])\n",
    "        \n",
    "        self._data = np.array(self._data)\n",
    "        self._labels = np.array(self._labels)\n",
    "\n",
    "        self._sentence_lengths = np.array(self._sentence_lengths)\n",
    "        self._final_tokens = np.array(self._final_tokens)\n",
    "        \n",
    "        self._num_epoch = 0\n",
    "        self._batch_id = 0\n",
    "        self._size = len(self._data)\n",
    "    \n",
    "    def next_batch(self):\n",
    "        start = self._batch_id * self._batch_size\n",
    "        end = start + self._batch_size\n",
    "        self._batch_id += 1\n",
    "        \n",
    "        if end + self._batch_size > len(self._data):\n",
    "            self._size = end\n",
    "            end = len(self._data)\n",
    "            start = end - self._batch_size\n",
    "            self._num_epoch += 1\n",
    "            self._batch_id = 0\n",
    "            indices = list(range(len(self._data)))\n",
    "            random.seed(2022)\n",
    "            random.shuffle(indices)\n",
    "            self._data, self._labels, self._sentence_lengths, self._final_tokens = \\\n",
    "                self._data[indices], self._labels[indices], self._sentence_lengths[indices], self._final_tokens[indices]\n",
    "            \n",
    "        \n",
    "        return self._data[start:end], self._labels[start:end], self._sentence_lengths[start:end], self._final_tokens[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23f94b8c-e722-448c-b848-90eed84e6fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_RNN():\n",
    "    with open('data/w2v/vocab-raw.txt') as f:\n",
    "        vocab_size = len(f.read().splitlines())\n",
    "        \n",
    "    tf.set_random_seed(2022)\n",
    "    rnn = RNN(\n",
    "        vocab_size=vocab_size,\n",
    "        embedding_size=300,\n",
    "        lstm_size=50,\n",
    "        batch_size=50\n",
    "    )\n",
    "    predicted_labels, loss = rnn.build_graph()\n",
    "    train_op = rnn.trainer(loss=loss, learning_rate=0.01)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        train_data_reader = DataReader(\n",
    "            data_path='data/w2v/20news-train-encoded.txt',\n",
    "            batch_size=50\n",
    "        )\n",
    "        \n",
    "        test_data_reader = DataReader(\n",
    "            data_path='data/w2v/20news-test-encoded.txt',\n",
    "            batch_size=50\n",
    "        )\n",
    "        step = 0\n",
    "        MAX_STEP = 10000\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        while step < MAX_STEP:\n",
    "            next_train_batch = train_data_reader.next_batch()\n",
    "            train_data, train_labels, train_sentence_lengths, train_final_tokens = next_train_batch\n",
    "            plabels_eval, loss_eval, _ = sess.run(\n",
    "                [predicted_labels, loss, train_op],\n",
    "                feed_dict={\n",
    "                    rnn._data: train_data,\n",
    "                    rnn._labels: train_labels,\n",
    "                    rnn._sentence_lengths: train_sentence_lengths,\n",
    "                    rnn._final_tokens: train_final_tokens\n",
    "                }\n",
    "            )\n",
    "            step += 1\n",
    "            if step % 20 == 0:\n",
    "                print(f'loss : {loss_eval}')\n",
    "            if train_data_reader._batch_id == 0:\n",
    "                num_true_preds = 0\n",
    "                while True:\n",
    "                    next_test_batch = test_data_reader.next_batch()\n",
    "                    test_data, test_labels, test_sentence_lengths, test_final_tokens = next_test_batch\n",
    "                    \n",
    "                    test_plabels_eval = sess.run(\n",
    "                        predicted_labels,\n",
    "                        feed_dict={\n",
    "                            rnn._data: test_data,\n",
    "                            rnn._labels: test_labels,\n",
    "                            rnn._sentence_lengths: test_sentence_lengths,\n",
    "                            rnn._final_tokens: test_final_tokens\n",
    "                        }\n",
    "                    )\n",
    "                    matches = np.equal(test_plabels_eval, test_labels)\n",
    "                    num_true_preds += np.sum(matches.astype(float))\n",
    "                    \n",
    "                    if test_data_reader._batch_id == 0:\n",
    "                        break\n",
    "                    \n",
    "                print(f'Epoch: {train_data_reader._num_epoch}')\n",
    "                print(f'Accuracy on test data: {num_true_preds * 100. / len(test_data_reader._data)}')\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ccda620-30a7-46df-8832-8e0997e652be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_23092\\809615805.py:35: BasicLSTMCell.__init__ (from tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_23092\\809615805.py:42: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From F:\\anacoda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:738: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From F:\\anacoda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:744: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From F:\\anacoda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "loss : 0.00014641157758887857\n",
      "loss : 0.04266723245382309\n",
      "loss : 10.160109519958496\n",
      "loss : 0.19843809306621552\n",
      "loss : 3.1871020793914795\n",
      "loss : 4.675797462463379\n",
      "loss : 2.5361227989196777\n",
      "loss : 2.606912851333618\n",
      "loss : 4.923043727874756\n",
      "loss : 4.946852207183838\n",
      "loss : 5.295243740081787\n",
      "Epoch: 1\n",
      "Accuracy on test data: 6.186935740839086\n",
      "loss : 2.7167890071868896\n",
      "loss : 2.506983757019043\n",
      "loss : 2.2391114234924316\n",
      "loss : 2.0996227264404297\n",
      "loss : 1.8732637166976929\n",
      "loss : 1.9685286283493042\n",
      "loss : 1.7312028408050537\n",
      "loss : 1.748155117034912\n",
      "loss : 1.724225640296936\n",
      "loss : 1.7341386079788208\n",
      "loss : 1.2165642976760864\n",
      "Epoch: 2\n",
      "Accuracy on test data: 67.08709506107276\n",
      "loss : 1.022554874420166\n",
      "loss : 1.1001659631729126\n",
      "loss : 1.0617587566375732\n",
      "loss : 0.8577679395675659\n",
      "loss : 1.0151853561401367\n",
      "loss : 0.623884379863739\n",
      "loss : 0.6868729591369629\n",
      "loss : 0.8814518451690674\n",
      "loss : 0.8104044198989868\n",
      "loss : 0.62666916847229\n",
      "loss : 0.6116767525672913\n",
      "Epoch: 3\n",
      "Accuracy on test data: 73.53956452469464\n",
      "loss : 0.45641031861305237\n",
      "loss : 0.35635849833488464\n",
      "loss : 0.35272735357284546\n",
      "loss : 0.41704586148262024\n",
      "loss : 0.33995354175567627\n",
      "loss : 0.36182335019111633\n",
      "loss : 0.3491675853729248\n",
      "loss : 0.348895788192749\n",
      "loss : 0.30201736092567444\n",
      "loss : 0.23578830063343048\n",
      "loss : 0.29329437017440796\n",
      "loss : 0.24841901659965515\n",
      "Epoch: 4\n",
      "Accuracy on test data: 75.1327668613914\n",
      "loss : 0.11442440003156662\n",
      "loss : 0.16834168136119843\n",
      "loss : 0.21453028917312622\n",
      "loss : 0.13307501375675201\n",
      "loss : 0.10826776176691055\n",
      "loss : 0.21157965064048767\n",
      "loss : 0.12904927134513855\n",
      "loss : 0.08558810502290726\n",
      "loss : 0.08765510469675064\n",
      "loss : 0.07681649178266525\n",
      "loss : 0.14224916696548462\n",
      "Epoch: 5\n",
      "Accuracy on test data: 75.9691980881572\n",
      "loss : 0.03267534822225571\n",
      "loss : 0.03090827539563179\n",
      "loss : 0.04953485354781151\n",
      "loss : 0.026004958897829056\n",
      "loss : 0.019846586510539055\n",
      "loss : 0.025656813755631447\n",
      "loss : 0.022414125502109528\n",
      "loss : 0.017837798222899437\n",
      "loss : 0.021805405616760254\n",
      "loss : 0.07822274416685104\n",
      "loss : 0.03326842188835144\n",
      "Epoch: 6\n",
      "Accuracy on test data: 75.47796070100902\n",
      "loss : 0.009472052566707134\n",
      "loss : 0.0071058813482522964\n",
      "loss : 0.012672334909439087\n",
      "loss : 0.006129005923867226\n",
      "loss : 0.005759513471275568\n",
      "loss : 0.011816021986305714\n",
      "loss : 0.008559600450098515\n",
      "loss : 0.017445387318730354\n",
      "loss : 0.00671541690826416\n",
      "loss : 0.009632823057472706\n",
      "loss : 0.006792759522795677\n",
      "loss : 0.013741339556872845\n",
      "Epoch: 7\n",
      "Accuracy on test data: 76.02230483271376\n",
      "loss : 0.005374779924750328\n",
      "loss : 0.005593917332589626\n",
      "loss : 0.003756969003006816\n",
      "loss : 0.006725586485117674\n",
      "loss : 0.004336101934313774\n",
      "loss : 0.0030195603612810373\n",
      "loss : 0.004150768276304007\n",
      "loss : 0.0045012179762125015\n",
      "loss : 0.031934697180986404\n",
      "loss : 0.002833709819242358\n",
      "loss : 0.004056057892739773\n",
      "Epoch: 8\n",
      "Accuracy on test data: 76.52681890600107\n",
      "loss : 0.001964202616363764\n",
      "loss : 0.0022695160005241632\n",
      "loss : 0.0030480886343866587\n",
      "loss : 0.0023377540055662394\n",
      "loss : 0.006158266682177782\n",
      "loss : 0.002177645219489932\n",
      "loss : 0.003402779111638665\n",
      "loss : 0.0023544796276837587\n",
      "loss : 0.0042911614291369915\n",
      "loss : 0.002267880830913782\n",
      "loss : 0.0033885815646499395\n",
      "Epoch: 9\n",
      "Accuracy on test data: 75.80987785448752\n",
      "loss : 0.0023327579256147146\n",
      "loss : 0.0021685417741537094\n",
      "loss : 0.001882083248347044\n",
      "loss : 0.001936418004333973\n",
      "loss : 0.0012729075970128179\n",
      "loss : 0.0017766430974006653\n",
      "loss : 0.003700547618791461\n",
      "loss : 0.0021181092597544193\n",
      "loss : 0.0008008190779946744\n",
      "loss : 0.004196395166218281\n",
      "loss : 0.0015857788966968656\n",
      "loss : 0.0016446232330054045\n",
      "Epoch: 10\n",
      "Accuracy on test data: 76.32766861391397\n",
      "loss : 0.0014033503830432892\n",
      "loss : 0.0013071761932224035\n",
      "loss : 0.001624771161004901\n",
      "loss : 0.0014054304920136929\n",
      "loss : 0.0016188088338822126\n",
      "loss : 0.0015743583207949996\n",
      "loss : 0.00888835173100233\n",
      "loss : 0.0015315951313823462\n",
      "loss : 0.001542013487778604\n",
      "loss : 0.0011123118456453085\n",
      "loss : 0.0009145543444901705\n",
      "Epoch: 11\n",
      "Accuracy on test data: 75.9691980881572\n",
      "loss : 0.001259331707842648\n",
      "loss : 0.0008958402322605252\n",
      "loss : 0.0007081188377924263\n",
      "loss : 0.0009701207745820284\n",
      "loss : 0.0037378889974206686\n",
      "loss : 0.0012492991518229246\n",
      "loss : 0.0010069102281704545\n",
      "loss : 0.0009218045161105692\n",
      "loss : 0.010931307449936867\n",
      "loss : 0.0016008514212444425\n",
      "loss : 0.0006306128343567252\n",
      "Epoch: 12\n",
      "Accuracy on test data: 76.47371216144451\n",
      "loss : 0.0006775943911634386\n",
      "loss : 0.0008445492130704224\n",
      "loss : 0.0012841022107750177\n",
      "loss : 0.0016055033775046468\n",
      "loss : 0.001501278718933463\n",
      "loss : 0.0007654178189113736\n",
      "loss : 0.0005792396259494126\n",
      "loss : 0.000538085529115051\n",
      "loss : 0.0006086709327064455\n",
      "loss : 0.0005328422412276268\n",
      "loss : 0.0007400481263175607\n",
      "Epoch: 13\n",
      "Accuracy on test data: 76.43388210302709\n",
      "loss : 0.0004731511289719492\n",
      "loss : 0.0006491152453236282\n",
      "loss : 0.0003412903461139649\n",
      "loss : 0.00034231049357913435\n",
      "loss : 0.0003931353858206421\n",
      "loss : 0.0006340749096125364\n",
      "loss : 0.0007713723462074995\n",
      "loss : 0.0004316462145652622\n",
      "loss : 0.0004496954788919538\n",
      "loss : 0.0009115979191847146\n",
      "loss : 0.0006397113902494311\n",
      "loss : 0.0006317568477243185\n",
      "Epoch: 14\n",
      "Accuracy on test data: 76.32766861391397\n",
      "loss : 0.0006488484796136618\n",
      "loss : 0.0003227091219741851\n",
      "loss : 0.000344301137374714\n",
      "loss : 0.00033320364309474826\n",
      "loss : 0.00040808378253132105\n",
      "loss : 0.00033134553814306855\n",
      "loss : 0.0004122910904698074\n",
      "loss : 0.0005469890311360359\n",
      "loss : 0.0004569772572722286\n",
      "loss : 0.0004911207943223417\n",
      "loss : 0.00041587845771573484\n",
      "Epoch: 15\n",
      "Accuracy on test data: 76.19490175252257\n",
      "loss : 0.00039222880150191486\n",
      "loss : 0.0002217255678260699\n",
      "loss : 0.0002985083556268364\n",
      "loss : 0.0003678096691146493\n",
      "loss : 0.0003493697149679065\n",
      "loss : 0.00031381778535433114\n",
      "loss : 0.0005006457795388997\n",
      "loss : 0.00037792508373968303\n",
      "loss : 0.0005009358865208924\n",
      "loss : 0.0004406995722092688\n",
      "loss : 0.0008684010826982558\n",
      "Epoch: 16\n",
      "Accuracy on test data: 76.4073287307488\n",
      "loss : 0.0003706597490236163\n",
      "loss : 0.00016240458353422582\n",
      "loss : 0.01633697934448719\n",
      "loss : 0.000421809934778139\n",
      "loss : 0.00020792947907466441\n",
      "loss : 0.00028749360353685915\n",
      "loss : 0.00016772326489444822\n",
      "loss : 0.00029197626281529665\n",
      "loss : 0.0005210838280618191\n",
      "loss : 0.0002788935962598771\n",
      "loss : 0.00027472455985844135\n",
      "loss : 0.00021307259157765657\n",
      "Epoch: 17\n",
      "Accuracy on test data: 76.52681890600107\n",
      "loss : 0.00020998621766921133\n",
      "loss : 0.0002434499328956008\n",
      "loss : 0.00014819276111666113\n",
      "loss : 0.00023962186241988093\n",
      "loss : 0.0008858130313456059\n",
      "loss : 0.00015309032460208982\n",
      "loss : 0.0003835708776023239\n",
      "loss : 0.0003655883192550391\n",
      "loss : 0.00028991300496272743\n",
      "loss : 0.0003121308400295675\n",
      "loss : 0.0002652320545166731\n",
      "Epoch: 18\n",
      "Accuracy on test data: 76.30111524163569\n",
      "loss : 0.00025397955323569477\n",
      "loss : 0.00018558057490736246\n",
      "loss : 0.00015400469419546425\n",
      "loss : 0.0001753272081259638\n",
      "loss : 0.00016005581710487604\n",
      "loss : 0.0002733374712988734\n",
      "loss : 0.00018597915186546743\n",
      "loss : 0.00013014199794270098\n",
      "loss : 0.0002675559080671519\n",
      "loss : 0.00013912147551309317\n",
      "loss : 0.0002745740348473191\n",
      "Epoch: 19\n",
      "Accuracy on test data: 76.63303239511418\n",
      "loss : 0.0002812229504343122\n",
      "loss : 0.00019476933812256902\n",
      "loss : 0.00019293329387437552\n",
      "loss : 0.00015535144484601915\n",
      "loss : 0.0004173288180027157\n",
      "loss : 0.00017288853996433318\n",
      "loss : 0.00021597268641926348\n",
      "loss : 0.00024960850714705884\n",
      "loss : 0.00015687498671468347\n",
      "loss : 0.00021935562836006284\n",
      "loss : 0.01786191202700138\n",
      "loss : 0.00022401234309654683\n",
      "Epoch: 20\n",
      "Accuracy on test data: 76.10196494954859\n",
      "loss : 0.0002212797844549641\n",
      "loss : 0.0001406969386152923\n",
      "loss : 0.00010281093273079023\n",
      "loss : 0.0001754250261001289\n",
      "loss : 0.0001353525440208614\n",
      "loss : 0.00017269649833906442\n",
      "loss : 0.0001321161980740726\n",
      "loss : 0.02365667186677456\n",
      "loss : 0.00022108532721176744\n",
      "loss : 0.00013483886141330004\n",
      "loss : 0.0001332154351985082\n",
      "Epoch: 21\n",
      "Accuracy on test data: 76.1683483802443\n",
      "loss : 0.0001417760649928823\n",
      "loss : 9.952123946277425e-05\n",
      "loss : 0.00013994793698657304\n",
      "loss : 0.00016100547509267926\n",
      "loss : 0.016689185053110123\n",
      "loss : 0.00013242510613054037\n",
      "loss : 0.00014861255476716906\n",
      "loss : 0.00017615921387914568\n",
      "loss : 0.0002425231650704518\n",
      "loss : 0.0010364199988543987\n",
      "loss : 9.03558757272549e-05\n",
      "Epoch: 22\n",
      "Accuracy on test data: 76.69941582580988\n",
      "loss : 6.92333051119931e-05\n",
      "loss : 0.00012010625505354255\n",
      "loss : 0.00011693663691403344\n",
      "loss : 0.00011082978016929701\n",
      "loss : 8.023675763979554e-05\n",
      "loss : 0.00011230116797378287\n",
      "loss : 0.00011400337098166347\n",
      "loss : 0.00012934100232087076\n",
      "loss : 0.00011875366180902347\n",
      "loss : 9.756714280229062e-05\n",
      "loss : 0.00014934889622963965\n",
      "Epoch: 23\n",
      "Accuracy on test data: 76.2081784386617\n",
      "loss : 6.841649883426726e-05\n",
      "loss : 0.00010828085214598104\n",
      "loss : 9.865564061328769e-05\n",
      "loss : 0.00011607282067416236\n",
      "loss : 8.978771802503616e-05\n",
      "loss : 0.0001385221694363281\n",
      "loss : 0.00014022381219547242\n",
      "loss : 0.00013589071750175208\n",
      "loss : 0.00010575135820545256\n",
      "loss : 0.00023475450871046633\n",
      "loss : 0.00028711327468045056\n",
      "loss : 0.00012926403724122792\n",
      "Epoch: 24\n",
      "Accuracy on test data: 75.41157727031333\n",
      "loss : 0.0043928613886237144\n",
      "loss : 0.0010320539586246014\n",
      "loss : 0.0004348479269538075\n",
      "loss : 0.000372731767129153\n",
      "loss : 0.0014607739867642522\n",
      "loss : 0.0012386664748191833\n",
      "loss : 0.01948894001543522\n",
      "loss : 0.40908920764923096\n",
      "loss : 0.46356627345085144\n",
      "loss : 0.2184056043624878\n",
      "loss : 0.4006340801715851\n",
      "Epoch: 25\n",
      "Accuracy on test data: 70.47265002655337\n",
      "loss : 0.12092482298612595\n",
      "loss : 0.22688136994838715\n",
      "loss : 0.3036779463291168\n",
      "loss : 0.2623695433139801\n",
      "loss : 0.14191854000091553\n",
      "loss : 0.13526535034179688\n",
      "loss : 0.1454293429851532\n",
      "loss : 0.12627293169498444\n",
      "loss : 0.23729802668094635\n",
      "loss : 0.11147728562355042\n",
      "loss : 0.2451310008764267\n",
      "Epoch: 26\n",
      "Accuracy on test data: 74.69463621879979\n",
      "loss : 0.01983247511088848\n",
      "loss : 0.0838918462395668\n",
      "loss : 0.033679019659757614\n",
      "loss : 0.010911042802035809\n",
      "loss : 0.01433983352035284\n",
      "loss : 0.034951671957969666\n",
      "loss : 0.013933838345110416\n",
      "loss : 0.022612283006310463\n",
      "loss : 0.0048133269883692265\n",
      "loss : 0.013651992194354534\n",
      "loss : 0.018672741949558258\n",
      "loss : 0.0279944259673357\n",
      "Epoch: 27\n",
      "Accuracy on test data: 75.02655337227829\n",
      "loss : 0.005187764763832092\n",
      "loss : 0.006260903086513281\n",
      "loss : 0.005398409441113472\n",
      "loss : 0.004204853903502226\n",
      "loss : 0.003717836458235979\n",
      "loss : 0.0069020651280879974\n",
      "loss : 0.004957105498760939\n",
      "loss : 0.005291540641337633\n",
      "loss : 0.006981582846492529\n",
      "loss : 0.005507778376340866\n",
      "loss : 0.003652786836028099\n",
      "Epoch: 28\n",
      "Accuracy on test data: 75.54434413170473\n",
      "loss : 0.0038757757283747196\n",
      "loss : 0.013583195395767689\n",
      "loss : 0.002405851148068905\n",
      "loss : 0.0036200685426592827\n",
      "loss : 0.002405745442956686\n",
      "loss : 0.0022088063415139914\n",
      "loss : 0.002803875831887126\n",
      "loss : 0.002323414431884885\n",
      "loss : 0.0019787831697613\n",
      "loss : 0.0024027961771935225\n",
      "loss : 0.002625910099595785\n",
      "Epoch: 29\n",
      "Accuracy on test data: 75.78332448220924\n",
      "loss : 0.01612604223191738\n",
      "loss : 0.005043785087764263\n",
      "loss : 0.001916395965963602\n",
      "loss : 0.002123844576999545\n",
      "loss : 0.0014598369598388672\n",
      "loss : 0.0010507937986403704\n",
      "loss : 0.0020772286225110292\n",
      "loss : 0.0019764115568250418\n",
      "loss : 0.0014899424277245998\n",
      "loss : 0.001390822697430849\n",
      "loss : 0.001648050849325955\n",
      "loss : 0.010480958968400955\n",
      "Epoch: 30\n",
      "Accuracy on test data: 75.90281465746149\n",
      "loss : 0.001242000493220985\n",
      "loss : 0.0019643958657979965\n",
      "loss : 0.001549626118503511\n",
      "loss : 0.0008853519102558494\n",
      "loss : 0.001465110806748271\n",
      "loss : 0.0008692751871421933\n",
      "loss : 0.0013883773935958743\n",
      "loss : 0.0010870288824662566\n",
      "loss : 0.001382538233883679\n",
      "loss : 0.0012779979733750224\n",
      "loss : 0.0018398400861769915\n",
      "Epoch: 31\n",
      "Accuracy on test data: 76.10196494954859\n",
      "loss : 0.0009655595058575273\n",
      "loss : 0.000826010771561414\n",
      "loss : 0.0016530086286365986\n",
      "loss : 0.001429579802788794\n",
      "loss : 0.001134540420025587\n",
      "loss : 0.0013609604211524129\n",
      "loss : 0.0010750663932412863\n",
      "loss : 0.0009540632599964738\n",
      "loss : 0.0012479581637308002\n",
      "loss : 0.000885594345163554\n",
      "loss : 0.001094888779334724\n",
      "Epoch: 32\n",
      "Accuracy on test data: 76.26128518321826\n",
      "loss : 0.001248006708920002\n",
      "loss : 0.00145079311914742\n",
      "loss : 0.00100786704570055\n",
      "loss : 0.0011545616434887052\n",
      "loss : 0.0008080916595645249\n",
      "loss : 0.00042390526505187154\n",
      "loss : 0.0008217825088649988\n",
      "loss : 0.0009556917357258499\n",
      "loss : 0.0007652401691302657\n",
      "loss : 0.0011881698155775666\n",
      "loss : 0.0007083862437866628\n",
      "Epoch: 33\n",
      "Accuracy on test data: 76.11524163568774\n",
      "loss : 0.0006791589548811316\n",
      "loss : 0.0004955874173901975\n",
      "loss : 0.0005651163519360125\n",
      "loss : 0.0007604934507980943\n",
      "loss : 0.001218765857629478\n",
      "loss : 0.0010443797800689936\n",
      "loss : 0.0005952806677669287\n",
      "loss : 0.0007988418801687658\n",
      "loss : 0.0006524607306346297\n",
      "loss : 0.00038755955756641924\n",
      "loss : 0.0009005229803733528\n",
      "loss : 0.00043147109681740403\n",
      "Epoch: 34\n",
      "Accuracy on test data: 76.31439192777482\n",
      "loss : 0.0007004612125456333\n",
      "loss : 0.0006864506285637617\n",
      "loss : 0.0005474684294313192\n",
      "loss : 0.0004791274550370872\n",
      "loss : 0.000921275932341814\n",
      "loss : 0.0005946866585873067\n",
      "loss : 0.0007551903836429119\n",
      "loss : 0.0004325019253883511\n",
      "loss : 0.0005081737763248384\n",
      "loss : 0.0006697686039842665\n",
      "loss : 0.0005707918899133801\n",
      "Epoch: 35\n",
      "Accuracy on test data: 76.00902814657462\n",
      "loss : 0.008544722571969032\n",
      "loss : 0.0005015861825086176\n",
      "loss : 0.0003610028943512589\n",
      "loss : 0.0005237599252723157\n",
      "loss : 0.009017886593937874\n",
      "loss : 0.0005205422639846802\n",
      "loss : 0.000794180785305798\n",
      "loss : 0.0007025208906270564\n",
      "loss : 0.0005195313133299351\n",
      "loss : 0.006058023776859045\n",
      "loss : 0.00358001422137022\n",
      "Epoch: 36\n",
      "Accuracy on test data: 76.30111524163569\n",
      "loss : 0.006946324836462736\n",
      "loss : 0.0005397781496867537\n",
      "loss : 0.0006017943378537893\n",
      "loss : 0.0005544299492612481\n",
      "loss : 0.0004185704456176609\n",
      "loss : 0.0005859041120857\n",
      "loss : 0.00045856463839299977\n",
      "loss : 0.0005131163052283227\n",
      "loss : 0.0004653722862713039\n",
      "loss : 0.0005650602979585528\n",
      "loss : 0.0005371060688048601\n",
      "loss : 0.0003006856713909656\n",
      "Epoch: 37\n",
      "Accuracy on test data: 76.36749867233138\n",
      "loss : 0.0003549804678186774\n",
      "loss : 0.000323994318023324\n",
      "loss : 0.0003856369003187865\n",
      "loss : 0.00047043428639881313\n",
      "loss : 0.0008167902124114335\n",
      "loss : 0.0004662094870582223\n",
      "loss : 0.0005779724451713264\n",
      "loss : 0.00046972904237918556\n",
      "loss : 0.00046163835213519633\n",
      "loss : 0.00037434243131428957\n",
      "loss : 0.00033917714608833194\n",
      "Epoch: 38\n",
      "Accuracy on test data: 76.47371216144451\n",
      "loss : 0.0004039295017719269\n",
      "loss : 0.0004968636203557253\n",
      "loss : 0.0006006601615808904\n",
      "loss : 0.000470485509140417\n",
      "loss : 0.00025320687564089894\n",
      "loss : 0.0004951018490828574\n",
      "loss : 0.00027385615976527333\n",
      "loss : 0.00041997196967713535\n",
      "loss : 0.0005256743752397597\n",
      "loss : 0.0005057002417743206\n",
      "loss : 0.0003772435593418777\n",
      "Epoch: 39\n",
      "Accuracy on test data: 76.27456186935741\n",
      "loss : 0.00031372590456157923\n",
      "loss : 0.0003667371638584882\n",
      "loss : 0.0003343932330608368\n",
      "loss : 0.0005874570924788713\n",
      "loss : 0.0002917473029810935\n",
      "loss : 0.0004198225506115705\n",
      "loss : 0.001872183638624847\n",
      "loss : 0.0003544679202605039\n",
      "loss : 0.000883627450093627\n",
      "loss : 0.0004968175198882818\n",
      "loss : 0.0003856185358017683\n",
      "loss : 0.0003267945721745491\n",
      "Epoch: 40\n",
      "Accuracy on test data: 76.59320233669676\n",
      "loss : 0.00021132954861968756\n",
      "loss : 0.00021137867588549852\n",
      "loss : 0.00029210103093646467\n",
      "loss : 0.00028024299535900354\n",
      "loss : 0.0003038313880097121\n",
      "loss : 0.00016618758672848344\n",
      "loss : 0.0016846999060362577\n",
      "loss : 0.0003982175840064883\n",
      "loss : 0.0005093268118798733\n",
      "loss : 0.00045419216621667147\n",
      "loss : 0.01044281106442213\n",
      "Epoch: 41\n",
      "Accuracy on test data: 76.57992565055763\n",
      "loss : 0.00011115990491816774\n",
      "loss : 0.00022810662630945444\n",
      "loss : 0.00024518565624020994\n",
      "loss : 0.00019954133313149214\n",
      "loss : 0.0003753119090106338\n",
      "loss : 0.0007339731091633439\n",
      "loss : 0.00024506720365025103\n",
      "loss : 0.00026477250503376126\n",
      "loss : 0.0002648632216732949\n",
      "loss : 0.0009369754698127508\n",
      "loss : 0.00027962870080955327\n",
      "Epoch: 42\n",
      "Accuracy on test data: 76.35422198619224\n",
      "loss : 0.0002876881044358015\n",
      "loss : 0.00038436937029473484\n",
      "loss : 0.000244883936829865\n",
      "loss : 0.00022340167197398841\n",
      "loss : 0.0003449984942562878\n",
      "loss : 0.00020289872190915048\n",
      "loss : 0.00017433043103665113\n",
      "loss : 0.0003151788841933012\n",
      "loss : 0.00022511451970785856\n",
      "loss : 0.00017188065976370126\n",
      "loss : 0.0002973343653138727\n",
      "Epoch: 43\n",
      "Accuracy on test data: 76.6064790228359\n",
      "loss : 0.0001587645529070869\n",
      "loss : 0.0003476383863016963\n",
      "loss : 0.0001933367020683363\n",
      "loss : 0.00044068924034945667\n",
      "loss : 0.0002303128712810576\n",
      "loss : 0.0002783673699013889\n",
      "loss : 0.0003486248606350273\n",
      "loss : 0.0001669893244979903\n",
      "loss : 0.00025014267885126173\n",
      "loss : 0.0002583912864793092\n",
      "loss : 0.00019320745195727795\n",
      "loss : 0.00020031486928928643\n",
      "Epoch: 44\n",
      "Accuracy on test data: 76.59320233669676\n",
      "loss : 0.00021304574329406023\n",
      "loss : 0.00014764021034352481\n",
      "loss : 0.00016653153579682112\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_RNN()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
