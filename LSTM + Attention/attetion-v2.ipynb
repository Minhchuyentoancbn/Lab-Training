{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom keras import backend as K\n\nfrom tensorflow.keras.preprocessing.text import text_to_word_sequence, Tokenizer\nfrom tensorflow.keras.layers import Embedding, Input, Dense, LSTM, GRU, Bidirectional, TimeDistributed\nfrom tensorflow.keras.models import Sequential, Model\nimport tensorflow.keras.initializers as initializers\nimport tensorflow.keras.regularizers as regularizers\nimport tensorflow.keras.constraints as constraints","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-28T13:04:58.597420Z","iopub.execute_input":"2022-10-28T13:04:58.598120Z","iopub.status.idle":"2022-10-28T13:05:00.238692Z","shell.execute_reply.started":"2022-10-28T13:04:58.598019Z","shell.execute_reply":"2022-10-28T13:05:00.237712Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"MAX_SENTENCES = 50\nMAX_WORDS_PER_SENTENCE = 50","metadata":{"execution":{"iopub.status.busy":"2022-10-28T13:05:00.240155Z","iopub.execute_input":"2022-10-28T13:05:00.240790Z","iopub.status.idle":"2022-10-28T13:05:00.246912Z","shell.execute_reply.started":"2022-10-28T13:05:00.240753Z","shell.execute_reply":"2022-10-28T13:05:00.244548Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def read_dataset(data_path):\n    with open(data_path) as f:\n        d_lines = f.read().splitlines()\n        \n    data = []\n    labels = []\n    for line in d_lines:\n        features = line.split('<fff>')\n        label, doc_id, sentences = int(features[0]), int(features[1]), features[2:]\n        \n        labels.append(label)\n        \n        doc_tokens = [] # contain tokens for every sentence in the doc\n        for sent in sentences:\n            sent_tokens = [int(token) for token in sent.split()]\n            doc_tokens.append(sent_tokens)\n            \n        data.append(doc_tokens)\n        \n    return np.array(data), np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T13:05:00.248402Z","iopub.execute_input":"2022-10-28T13:05:00.249145Z","iopub.status.idle":"2022-10-28T13:05:00.258315Z","shell.execute_reply.started":"2022-10-28T13:05:00.249102Z","shell.execute_reply":"2022-10-28T13:05:00.257343Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = read_dataset('../input/attention-v2/20news-train-encoded.txt')\nX_test, y_test = read_dataset('../input/attention-v2/20news-test-encoded.txt')\n\ny_train = pd.get_dummies(pd.Series(y_train)).values\ny_test = pd.get_dummies(pd.Series(y_test)).values","metadata":{"execution":{"iopub.status.busy":"2022-10-28T13:05:00.262352Z","iopub.execute_input":"2022-10-28T13:05:00.263302Z","iopub.status.idle":"2022-10-28T13:05:17.031805Z","shell.execute_reply.started":"2022-10-28T13:05:00.263267Z","shell.execute_reply":"2022-10-28T13:05:17.030814Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def dot_product(x, kernel):\n    \"\"\"\n    Wrapper for dot product operation, in order to be compatible with both\n    Theano and Tensorflow\n    Args:\n        x (): input\n        kernel (): weights\n    Returns:\n    \"\"\"\n    if K.backend() == 'tensorflow':\n        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n    else:\n        return K.dot(x, kernel)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T13:05:17.033315Z","iopub.execute_input":"2022-10-28T13:05:17.033699Z","iopub.status.idle":"2022-10-28T13:05:17.039606Z","shell.execute_reply.started":"2022-10-28T13:05:17.033664Z","shell.execute_reply":"2022-10-28T13:05:17.038513Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class AttentionWithContext(tf.keras.layers.Layer):\n    \n    def __init__(self,\n                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n                 W_constraint=None, u_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.u_regularizer = regularizers.get(u_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.u_constraint = constraints.get(u_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        super(AttentionWithContext, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        if self.bias:\n            self.b = self.add_weight(shape=(input_shape[-1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n\n        self.u = self.add_weight(shape=(input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_u'.format(self.name),\n                                 regularizer=self.u_regularizer,\n                                 constraint=self.u_constraint)\n\n        super(AttentionWithContext, self).build(input_shape)\n\n    def compute_mask(self, input, input_mask=None):\n        # do not pass the mask to the next layers\n        return None\n\n    def call(self, x, mask=None):\n        uit = dot_product(x, self.W)\n\n        if self.bias:\n            uit += self.b\n\n        uit = K.tanh(uit)\n        ait = dot_product(uit, self.u)\n\n        a = K.exp(ait)\n\n        # apply mask after the exp. will be re-normalized next\n        if mask is not None:\n            # Cast the mask to floatX to avoid float64 upcasting in theano\n            a *= K.cast(mask, K.floatx())\n\n        # in some cases especially in the early stages of training the sum may be almost zero\n        # and this results in NaN's. A workaround is to add a very small positive number Îµ to the sum.\n        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0], input_shape[-1]","metadata":{"execution":{"iopub.status.busy":"2022-10-28T13:05:17.041208Z","iopub.execute_input":"2022-10-28T13:05:17.041875Z","iopub.status.idle":"2022-10-28T13:05:17.057489Z","shell.execute_reply.started":"2022-10-28T13:05:17.041842Z","shell.execute_reply":"2022-10-28T13:05:17.056579Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"with open('../input/attention-set/vocab-raw.txt', 'rb') as f:\n    vocab_size = len(f.read().splitlines())","metadata":{"execution":{"iopub.status.busy":"2022-10-28T13:05:17.058657Z","iopub.execute_input":"2022-10-28T13:05:17.059568Z","iopub.status.idle":"2022-10-28T13:05:17.074356Z","shell.execute_reply.started":"2022-10-28T13:05:17.059518Z","shell.execute_reply":"2022-10-28T13:05:17.073341Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"embedding_layer = Embedding(\n    input_dim=vocab_size+2, output_dim=300, input_length=MAX_WORDS_PER_SENTENCE\n)\n\nword_input = Input(shape=(MAX_WORDS_PER_SENTENCE, ), dtype='int32')\nword_sequence = embedding_layer(word_input)\nword_lstm = Bidirectional(LSTM(units=100, return_sequences=True))(word_sequence)\nword_dense = TimeDistributed(Dense(200))(word_lstm)\nword_att = AttentionWithContext()(word_dense)\nwordEncoder = Model(word_input, word_att)\n\nsent_input = Input(\n    shape=(MAX_SENTENCES, MAX_WORDS_PER_SENTENCE), dtype='int32')\nsent_encoder = TimeDistributed(wordEncoder)(sent_input)\nsent_lstm = Bidirectional(LSTM(100, return_sequences=True))(sent_encoder)\nsent_dense = TimeDistributed(Dense(200))(sent_lstm)\nsent_att = AttentionWithContext()(sent_dense)\npreds = Dense(20, activation='softmax')(sent_att)\nmodel = Model(sent_input, preds)\n\nmodel.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n              optimizer='adam',\n              metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2022-10-28T13:05:17.075777Z","iopub.execute_input":"2022-10-28T13:05:17.076261Z","iopub.status.idle":"2022-10-28T13:05:20.035773Z","shell.execute_reply.started":"2022-10-28T13:05:17.076223Z","shell.execute_reply":"2022-10-28T13:05:20.034781Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2022-10-28 13:05:17.131978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-28 13:05:17.140760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-28 13:05:17.141425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-28 13:05:17.142606: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-10-28 13:05:17.142896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-28 13:05:17.143590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-28 13:05:17.144216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-28 13:05:17.788226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-28 13:05:17.789044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-28 13:05:17.789724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-28 13:05:17.790306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(X_train, y_train, validation_split=0.1,\n          epochs=20, batch_size=100)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T13:05:20.040287Z","iopub.execute_input":"2022-10-28T13:05:20.047328Z","iopub.status.idle":"2022-10-28T13:13:06.860472Z","shell.execute_reply.started":"2022-10-28T13:05:20.047284Z","shell.execute_reply":"2022-10-28T13:13:06.859458Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2022-10-28 13:05:20.517804: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2022-10-28 13:05:26.515026: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"102/102 [==============================] - 31s 241ms/step - loss: 2.6447 - acc: 0.1221 - val_loss: 6.4590 - val_acc: 0.0000e+00\nEpoch 2/20\n102/102 [==============================] - 23s 224ms/step - loss: 1.3583 - acc: 0.4955 - val_loss: 7.2042 - val_acc: 0.2032\nEpoch 3/20\n102/102 [==============================] - 23s 224ms/step - loss: 0.4935 - acc: 0.8372 - val_loss: 7.6323 - val_acc: 0.2129\nEpoch 4/20\n102/102 [==============================] - 23s 224ms/step - loss: 0.1609 - acc: 0.9519 - val_loss: 9.5672 - val_acc: 0.2164\nEpoch 5/20\n102/102 [==============================] - 23s 224ms/step - loss: 0.0650 - acc: 0.9823 - val_loss: 9.7841 - val_acc: 0.2253\nEpoch 6/20\n102/102 [==============================] - 23s 223ms/step - loss: 0.0345 - acc: 0.9911 - val_loss: 10.0531 - val_acc: 0.2253\nEpoch 7/20\n102/102 [==============================] - 23s 224ms/step - loss: 0.0259 - acc: 0.9930 - val_loss: 10.3890 - val_acc: 0.2270\nEpoch 8/20\n102/102 [==============================] - 23s 224ms/step - loss: 0.0143 - acc: 0.9972 - val_loss: 11.0180 - val_acc: 0.2182\nEpoch 9/20\n102/102 [==============================] - 23s 224ms/step - loss: 0.0186 - acc: 0.9950 - val_loss: 11.0496 - val_acc: 0.2147\nEpoch 10/20\n102/102 [==============================] - 23s 223ms/step - loss: 0.0274 - acc: 0.9929 - val_loss: 11.6808 - val_acc: 0.1943\nEpoch 11/20\n102/102 [==============================] - 23s 223ms/step - loss: 0.0186 - acc: 0.9949 - val_loss: 10.6213 - val_acc: 0.2261\nEpoch 12/20\n102/102 [==============================] - 23s 225ms/step - loss: 0.0245 - acc: 0.9932 - val_loss: 10.6239 - val_acc: 0.2226\nEpoch 13/20\n102/102 [==============================] - 23s 224ms/step - loss: 0.0206 - acc: 0.9937 - val_loss: 10.3949 - val_acc: 0.2261\nEpoch 14/20\n102/102 [==============================] - 23s 226ms/step - loss: 0.0152 - acc: 0.9956 - val_loss: 10.3462 - val_acc: 0.2094\nEpoch 15/20\n102/102 [==============================] - 23s 226ms/step - loss: 0.0152 - acc: 0.9961 - val_loss: 11.9008 - val_acc: 0.1988\nEpoch 16/20\n102/102 [==============================] - 23s 226ms/step - loss: 0.0098 - acc: 0.9973 - val_loss: 11.2114 - val_acc: 0.2094\nEpoch 17/20\n102/102 [==============================] - 23s 226ms/step - loss: 0.0045 - acc: 0.9988 - val_loss: 11.2285 - val_acc: 0.2111\nEpoch 18/20\n102/102 [==============================] - 23s 227ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 10.9935 - val_acc: 0.2155\nEpoch 19/20\n102/102 [==============================] - 23s 226ms/step - loss: 0.0020 - acc: 0.9993 - val_loss: 11.3272 - val_acc: 0.2120\nEpoch 20/20\n102/102 [==============================] - 23s 226ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 11.1903 - val_acc: 0.2120\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fe296472910>"},"metadata":{}}]},{"cell_type":"code","source":"model.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T13:13:06.863495Z","iopub.execute_input":"2022-10-28T13:13:06.863821Z","iopub.status.idle":"2022-10-28T13:13:13.616750Z","shell.execute_reply.started":"2022-10-28T13:13:06.863793Z","shell.execute_reply":"2022-10-28T13:13:13.615876Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"236/236 [==============================] - 6s 27ms/step - loss: 2.3221 - acc: 0.7435\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[2.3221399784088135, 0.74349445104599]"},"metadata":{}}]}]}